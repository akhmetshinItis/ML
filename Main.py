import os
import librosa
import numpy as np
import pandas as pd
from pydub import AudioSegment
from collections import Counter
import tempfile
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.decomposition import PCA

# -----------------------------
# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
# -----------------------------

data_dir = "/Users/tagirahmetsin/Downloads/16000_pcm_speeches"

speakers = [s for s in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, s)) and s not in ["background_noise", "other", "_background_noise_", ".DS_Store"]]
print("–°–ø–∏—Å–æ–∫ —Å–ø–∏–∫–µ—Ä–æ–≤:", speakers)

train_file_paths = []
train_labels = []
test_file_paths = []
test_labels = []

# 1.1 –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ train/test
for speaker in speakers:
    speaker_folder = os.path.join(data_dir, speaker)
    speaker_files = [f for f in os.listdir(speaker_folder) if f.endswith(".wav")]
    full_paths = [os.path.join(speaker_folder, f) for f in speaker_files]
    labels_ = [speaker] * len(full_paths)
    train_files, test_files, train_labs, test_labs = train_test_split(
        full_paths, labels_, test_size=0.8, random_state=42
    )
    train_file_paths.extend(train_files)
    train_labels.extend(train_labs)
    test_file_paths.extend(test_files)
    test_labels.extend(test_labs)

# 1.2 –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —à—É–º–æ–≤
background_noise_dir = os.path.join(data_dir, "_background_noise_")
temp_noise_paths = []
if os.path.exists(background_noise_dir):
    for file in os.listdir(background_noise_dir):
        if file.endswith(".wav"):
            noise_audio = AudioSegment.from_wav(os.path.join(background_noise_dir, file))
            for i, start in enumerate(range(0, len(noise_audio), 1000)):
                end = min(start + 1000, len(noise_audio))
                chunk = noise_audio[start:end]
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_wav:
                    chunk.export(tmp_wav.name, format="wav")
                    train_file_paths.append(tmp_wav.name)
                    train_labels.append("noise")
                    temp_noise_paths.append(tmp_wav.name)

# -----------------------------
# 2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
# -----------------------------

def extract_features(file_path):
    audio, sr = librosa.load(file_path, sr=16000)
    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13, n_fft=512)
    delta = librosa.feature.delta(mfcc)
    delta2 = librosa.feature.delta(mfcc, order=2)
    chroma = librosa.feature.chroma_stft(y=audio, sr=sr)
    contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)
    zcr = librosa.feature.zero_crossing_rate(y=audio)
    rms = librosa.feature.rms(y=audio)

    combined = np.vstack([mfcc, delta, delta2, chroma, contrast, zcr, rms])
    mean = np.mean(combined, axis=1)
    std = np.std(combined, axis=1)
    median = np.median(combined, axis=1)
    return np.hstack([mean, std, median])

def extract_features_batch(paths, labels):
    features = []
    valid_labels = []
    for i, path in enumerate(paths):
        try:
            feat = extract_features(path)
            features.append(feat)
            valid_labels.append(labels[i])
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {path}: {e}")
    return np.array(features), np.array(valid_labels)

X_train_raw, y_train = extract_features_batch(train_file_paths, train_labels)
X_test_raw, y_test = extract_features_batch(test_file_paths, test_labels)

# -----------------------------
# 3. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
# -----------------------------

X_train_mean = X_train_raw.mean(axis=0)
X_train_std = X_train_raw.std(axis=0)

def normalize(X, mean, std):
    return (X - mean) / (std + 1e-8)

X_train_norm = normalize(X_train_raw, X_train_mean, X_train_std)
X_test_norm = normalize(X_test_raw, X_train_mean, X_train_std)

# -----------------------------
# 4. PCA
# -----------------------------

pca = PCA(n_components=30)
X_train = pca.fit_transform(X_train_norm)
X_test = pca.transform(X_test_norm)

# -----------------------------
# 5. kNN –∏ –ø–æ–¥–±–æ—Ä –ª—É—á—à–µ–≥–æ k
# -----------------------------

def euclidean_distance(a, b):
    return np.sqrt(np.sum((a - b) ** 2))

def knn_predict(X_train, y_train, x_test, k=5):
    distances = [(euclidean_distance(x_test, x), y) for x, y in zip(X_train, y_train)]
    distances.sort(key=lambda x: x[0])
    k_neighbors = distances[:k]
    labels = [neighbor[1] for neighbor in k_neighbors]
    most_common = Counter(labels).most_common(1)
    return most_common[0][0]

accuracies = []
k_values = [26]
all_preds = {}

print("\nüìà –ü–æ–¥–±–æ—Ä –ª—É—á—à–µ–≥–æ k:")
for k in k_values:
    y_pred_k = [knn_predict(X_train, y_train, x, k=k) for x in X_test]
    acc = accuracy_score(y_test, y_pred_k)
    print(f"k = {k:2d} ‚Üí Accuracy = {acc:.4f}")
    accuracies.append(acc)
    all_preds[k] = y_pred_k

# -----------------------------
# 6. –í—ã–±–æ—Ä –∏ –≤—ã–≤–æ–¥ –ª—É—á—à–µ–≥–æ k
# -----------------------------

fixed_k = 26
print(f"\nüìå –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ k = {fixed_k}")
y_pred = [knn_predict(X_train, y_train, x, k=fixed_k) for x in X_test]
acc = accuracy_score(y_test, y_pred)
print(f"‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–∏ k = {fixed_k}: {acc:.4f}")
print("\nüîç –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç:")

# -----------------------------
# 8. –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
# -----------------------------

for path in temp_noise_paths:
    try:
        os.remove(path)
    except Exception:
        pass
import os
import librosa
import numpy as np
import pandas as pd
from pydub import AudioSegment
from collections import Counter
import tempfile
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.decomposition import PCA

# -----------------------------
# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
# -----------------------------
data_dir = "/Users/tagirahmetsin/Downloads/16000_pcm_speeches"

speakers = [s for s in os.listdir(data_dir)
            if os.path.isdir(os.path.join(data_dir, s))
            and s not in ["background_noise", "other", "_background_noise_", ".DS_Store"]]
print("üé§ –ù–∞–π–¥–µ–Ω–æ —Å–ø–∏–∫–µ—Ä–æ–≤:", len(speakers))

train_file_paths, train_labels = [], []
test_file_paths, test_labels = [], []

for speaker in speakers:
    folder = os.path.join(data_dir, speaker)
    files = [f for f in os.listdir(folder) if f.endswith(".wav")]
    full_paths = [os.path.join(folder, f) for f in files]
    labels = [speaker] * len(full_paths)
    train, test, y_train_split, y_test_split = train_test_split(
        full_paths, labels, test_size=0.5, random_state=42)
    train_file_paths.extend(train)
    train_labels.extend(y_train_split)
    test_file_paths.extend(test)
    test_labels.extend(y_test_split)

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —à—É–º–æ–≤
background_noise_dir = os.path.join(data_dir, "_background_noise_")
temp_noise_paths = []
if os.path.exists(background_noise_dir):
    for file in os.listdir(background_noise_dir):
        if file.endswith(".wav"):
            audio = AudioSegment.from_wav(os.path.join(background_noise_dir, file))
            for i, start in enumerate(range(0, len(audio), 1000)):
                end = min(start + 1000, len(audio))
                chunk = audio[start:end]
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                    chunk.export(tmp.name, format="wav")
                    train_file_paths.append(tmp.name)
                    train_labels.append("noise")
                    temp_noise_paths.append(tmp.name)

# -----------------------------
# 2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
# -----------------------------
def extract_features(file_path):
    y, sr = librosa.load(file_path, sr=16000)
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, n_fft=512)
    delta = librosa.feature.delta(mfcc)
    delta2 = librosa.feature.delta(mfcc, order=2)
    chroma = librosa.feature.chroma_stft(y=y, sr=sr)
    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)
    zcr = librosa.feature.zero_crossing_rate(y=y)
    rms = librosa.feature.rms(y=y)
    combined = np.vstack([mfcc, delta, delta2, chroma, contrast, zcr, rms])
    return np.hstack([np.mean(combined, axis=1),
                      np.std(combined, axis=1),
                      np.median(combined, axis=1)])

def extract_features_batch(paths, labels):
    feats, valid_labels = [], []
    for path, label in zip(paths, labels):
        try:
            feats.append(extract_features(path))
            valid_labels.append(label)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {path}: {e}")
    return np.array(feats), np.array(valid_labels)

X_train_raw, y_train = extract_features_batch(train_file_paths, train_labels)
X_test_raw, y_test = extract_features_batch(test_file_paths, test_labels)

# -----------------------------
# 3. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
# -----------------------------
def normalize(X, mean, std):
    return (X - mean) / (std + 1e-8)

X_train_mean = X_train_raw.mean(axis=0)
X_train_std = X_train_raw.std(axis=0)
X_train_norm = normalize(X_train_raw, X_train_mean, X_train_std)
X_test_norm = normalize(X_test_raw, X_train_mean, X_train_std)

# -----------------------------
# 4. PCA
# -----------------------------
pca = PCA(n_components=30)
X_train = pca.fit_transform(X_train_norm)
X_test = pca.transform(X_test_norm)

# -----------------------------
# 5. kNN –∏ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ k
# -----------------------------
from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=fixed_k)
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)
print(classification_report(y_test, y_pred))
fixed_k = 26
print(f"\nüìå –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ k = {fixed_k}")
y_pred = [knn_predict(X_train, y_train, x, k=fixed_k) for x in X_test]

# -----------------------------
# 6. –û—Ç—á–µ—Ç—ã
# -----------------------------
accuracy = accuracy_score(y_test, y_pred)
print(f"\n‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ: {accuracy:.4f}")
print("\nüîç –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç:")
print(classification_report(y_test, y_pred))

# -----------------------------
# 7. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
# -----------------------------
plt.figure(figsize=(10, 6))
cm = confusion_matrix(y_test, y_pred, labels=np.unique(y_train))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=np.unique(y_train), yticklabels=np.unique(y_train))
plt.title(f"–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ (k = {fixed_k})")
plt.xlabel("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ")
plt.ylabel("–ò—Å—Ç–∏–Ω–Ω–æ")
plt.tight_layout()
plt.savefig("confusion_matrix_kNN.png")
print("üìä –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ confusion_matrix_kNN.png")
plt.close()

# -----------------------------
# 8. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Å–≤–æ—ë–º —Ñ–∞–π–ª–µ
# -----------------------------
def test_custom_file(file_path):
    print(f"\nüîé –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ñ–∞–π–ª–µ: {file_path}")
    try:
        features = extract_features(file_path)
        features = normalize(features, X_train_mean, X_train_std)
        features = pca.transform([features])
        prediction = knn_predict(X_train, y_train, features[0], k=fixed_k)
        print(f"üì¢ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å: {prediction}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")

# –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–æ–∫—É –∏ –≤—Å—Ç–∞–≤—å—Ç–µ –ø—É—Ç—å –∫ –≤–∞—à–µ–º—É —Ñ–∞–π–ª—É –¥–ª—è —Ç–µ—Å—Ç–∞:
test_custom_file("/Users/tagirahmetsin/Downloads/jul_16k.wav")

# -----------------------------
# 9. –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
# -----------------------------
for path in temp_noise_paths:
    try:
        os.remove(path)
    except:
        pass
